<html>
  <head>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.js"></script>
    <script src="https://unpkg.com/image-compare-viewer/dist/image-compare-viewer.min.js"></script>
    <link rel="stylesheet" href="https://unpkg.com/image-compare-viewer@1.4.1/dist/image-compare-viewer.min.css">

    
    <script type="module">
      import * as make_img from "./make_img.js";
      make_img.main();

      // alert("I have verified that the problem with with the output of predict. It is not the same as in pytorch. But the images from onnx and tfjs are the same, suggesting the problem is when saving to the onnx format.")

      isTesting();

      const DIMEN = 256;  // TODO: Read from IMG_SIZE in library, to avoid redundancy.

      function isTesting() {
        // For testing, copy image with known output onto canvas.

        const urlParams = new URLSearchParams(window.location.search);
        let idToTest = urlParams.get("test");
        if (idToTest !== null) {
          let canvas = document.getElementById('canvasRenderer');
          let context = canvas.getContext('2d');
          let base_image = new Image();
          base_image.src = `tests/${idToTest}/${idToTest}_real_A.png`;
          base_image.onload = () => {
            // TODO: Should wait to proceed until this is finished (w/ promise).
            context.drawImage(base_image, 0, 0);
          };

          let compare_path = `tests/${idToTest}/${idToTest}_real_A.png`;
          // let compare_path = `tests/${idToTest}/${idToTest}_real_B.png`;
          // let compare_path = `tests/${idToTest}/${idToTest}_fake_B.png`;
          // let compare_path = `tests/${idToTest}/${idToTest}_fake_B_onnx.png`;
          document.getElementById("label").innerHTML = "browser image ==> " + compare_path;
          
          // On left
          document.getElementById("orig").src = compare_path;
        }
      }

      function imgTransform(img) {
        // Adapted from
        // https://stackoverflow.com/questions/66371667/how-to-normalize-image-in-tensorflow-js
        // img = tf.image.resizeBilinear(img, [DIMEN, DIMEN]).div(tf.scalar(255));
        img = tf.image.resizeBilinear(img, [DIMEN, DIMEN]);
        img = tf.cast(img, "float32").reshape([DIMEN, DIMEN, 3]);

        let use_new = true;

        let processedImg

        if (use_new) {
          // The tensorflow implementation is much simplier
          processedImg = img.div(127.5).add(-1.0).transpose([2, 0, 1]).reshape([1, 3, DIMEN, DIMEN])
        } else {
          // mean of image
          // let mm = tf.moments(img, [0, 1]);
          // let means = mm.mean.add(0.5).arraySync();
          let meanRgb = { red: 0.5, green: 0.5, blue: 0.5 };
  
          /* standard deviation of natural image*/
          // let stdevs = mm.variance.add(0.5).arraySync();
          let stdRgb = { 
              red: 0.5, 
              green: 0.5, 
              blue: 0.5 
          };
  
          let indices = [
            tf.tensor1d([0], "int32"),
            tf.tensor1d([1], "int32"),
            tf.tensor1d([2], "int32"),
          ];
  
          // Separate channels into their own tensor and normalize
          let centeredRed = tf
            .gather(img, indices[0], 2)
            .sub(tf.scalar(meanRgb.red))
            .div(tf.scalar(stdRgb.red))
            .reshape([DIMEN, DIMEN]);
  
          let centeredGreen = tf
            .gather(img, indices[1], 2)
            .sub(tf.scalar(meanRgb.green))
            .div(tf.scalar(stdRgb.green))
            .reshape([DIMEN, DIMEN]);
  
          let centeredBlue = tf
            .gather(img, indices[2], 2)
            .sub(tf.scalar(meanRgb.blue))
            .div(tf.scalar(stdRgb.blue))
            .reshape([DIMEN, DIMEN]);
  
          // combining seperate normalized channels. Note that this switches to
          // channel first.
          processedImg = tf
            .stack([centeredRed, centeredGreen, centeredBlue])
            .expandDims();
        }

        // debugger; // [1,3,1024,1024]
        console.log("processedImg should range for -1 to 1 based on the python script.")
        console.log(processedImg.min().print(true));
        console.log(processedImg.max().print(true));

        return processedImg;
      }

      // tf.loadGraphModel("./model/model.json").then((model) => {
      tf.loadLayersModel("./model/model.json").then((model) => {
        // Get data from canvas image
        let canvas = document.getElementById("canvasRenderer");
        let context = canvas.getContext("2d");
        const image = context.getImageData(0, 0, DIMEN, DIMEN);

        let tensorFromCanvas = tf.browser
          .fromPixels(image)
          .reshape([1, DIMEN, DIMEN, 3]);

        let tensor = imgTransform(tensorFromCanvas);

        // Must convert to channel last format. Otherwise, Uncaught (in promise)
        // Error: Error when checking : expected input_1 to have shape
        // [null,1024,1024,3] but got array with shape [1,3,1024,1024].
        tensor = tensor.transpose([0, 2, 3, 1]);

        // Most convert to channel-first format. See
        // https://stackoverflow.com/questions/37689423/convert-between-nhwc-and-nchw-in-tensorflow/37689717

        // tensor needs to range for -1 to 1. 
        // console.log("http://0.0.0.0:8000/test.html?test=0471202805568984")
        // console.log(tensor.arraySync()[0][512][521], "Should be: 1.       , -1.       ,  0.5921569")
        // console.log(tensor.arraySync()[0][512][650], "Should be: 1.      , -1.      ,  0.654902")
        // debugger

        // tensor = tf.browser.fromPixels(
        //   canvas
        // ).reshape([1, DIMEN, DIMEN, 3]);
        
        // NOTE: I did pretty extensive testing on 8-6-2021, and I think tensor
        // is the same as in the pytorch implentation (within rounding error).
        debugger
        let result = model.predict(tensor);
        debugger

        // let adding = []
        // let vals = result.arraySync()[0];
        // for (var val of vals) {
        //   for (var val2 of val) {
        //     adding = adding.concat(val2);
        //   }
        // }
        

        // Helper function
        let getWeights = function() {
          console.log("Finding...");
          let weights = model.getWeights();
          let proms = weights.map(w => w.data());
          Promise.all(proms).then((weights) => {
            for (let i=0; i<weights.length; i++) {
              let weight = weights[i];
              let s = (i+1).toString() + ": ";
              let min = 1000000;
              let max = -1000000;
              for (let j=0; j<weight.length; j++) {
                let v = weight[j];
                if (v < min) { min = v; }
                if (v > max) { max = v; }
              }
              s += min.toFixed(4) + " ";
              s += max.toFixed(4);
              console.log(s);
            };
          });
        }
        getWeights();

        // let getOutputs = function(layerNum) {
        //   debugger;
        //   const newModel = tf.model({inputs: model.inputs, outputs: model.layers[layerNum].output}); 
        //   const layerActivation = newModel.predict(inputValue);
        // }
        // getOutputs(0);
        // debugger

        // console.log("http://0.0.0.0:8000/test.html?test=0471202805568984")
        // console.log(result.arraySync()[0][512][521], "Should be: 0.4807829, -0.7110381, -0.6815838")
        // console.log(result.arraySync()[0][512][650], "Should be: -0.6974288 , -0.8019914 , -0.05762012")


        // output tensor should have dimens 1, 3, 1024, 1024.

        // NOTE: I did pretty exntensive testing on 8-6-2021, and result
        // different from what I see in pytorch. The trends in the tensor values
        // are similar, but not idential.

        // debugger;

        // let channelLast = tf
        //     .transpose(result, [0, 2, 3, 1])
        //     .reshape([1024, 1024, 3])
        //     .add(1.0)
        //     .div(2.0)
        //     .mul(255.0);
        let channelLast = result
            .reshape([DIMEN, DIMEN, 3])
            .add(1.0)
            .div(2.0)
            .mul(255.0);
        channelLast = tf.cast(channelLast, "int32");

        debugger;
        
        // https://js.tensorflow.org/api/1.0.0/#browser.toPixels
        let outImg = tf
            .browser
            .toPixels(channelLast, canvas)
            .then((data) => {
                // console.log(data);
                var target = new Image();
                target.src = canvas.toDataURL();
                const element = document.getElementById("image-compare");
                element.style.display = "block";
                element.style.width = DIMEN.toString() + "px";
                element.style.height = DIMEN.toString() + "px";
                element.appendChild(target);
                const viewer = new ImageCompare(element).mount();
                canvas.style.display = "none";
            })
      });
    </script>
  </head>
  <body>
    <div id="label"></div>
    <div id="image-compare" style="display:none;">
      <img id="orig" src="" alt="" />
    </div>

  </body>
</html>
